Gibin Joseph Geo
Task_3

Top Token Extraction using BioBERT Tokenizer

This script uses the AutoTokenizer from the dmis-lab/biobert-base-cased-v1.1 model to tokenize and count the most frequent tokens from a text file.
Overview

The script reads a text file (combined_text.txt), tokenizes its content, and counts the frequency of each token. It then filters the top 30 most frequent alphabetic tokens and writes them to a CSV file (top_30_tokens_using_AutoTokenizer.csv).
Output

    CSV File: top_30_tokens_using_AutoTokenizer.csv
        Columns: Token, Count
        Contains the top 30 most frequent alphabetic tokens and their counts.

Requirements

    transformers
    collections
    csv

Install the required library:

bash

pip install transformers

Usage

Run the script to extract and count the tokens from combined_text.txt. The results will be saved in the top_30_tokens_using_AutoTokenizer.csv file.

Task_4
Biomedical Named Entity Recognition and Comparison

This repository contains scripts for biomedical named entity recognition (NER) using various models (SpaCy and BioBERT) and comparison between extracted entities from multiple sources. The project primarily focuses on extracting drug and disease entities from a large text file and comparing the results from different NER models.
Files
1. spacy_en_ner_bc5cdr_md_entities_extraction.py

This script utilizes the SpaCy model (en_ner_bc5cdr_md) to perform named entity recognition for drug and disease entities.

    Input: A large text file (combined_text.txt).
    Process: The text is split into manageable chunks and processed for drug and disease entities.
    Output: The extracted entities are written into a CSV file (spacy_en_ner_bc5cdr_md_entities.csv) with columns Entity and Label.

How it works:

    The script loads the SpaCy model.
    The text is split into chunks of 1 million characters for processing.
    Only entities labeled as DISEASE or DRUG are extracted and written into the CSV file.

2. biobert_disease_entities_extraction.py

This script uses the BioBERT model (ugaray96/biobert_ncbi_disease_ner) to extract disease entities from a text file.

    Input: A large text file (combined_text.txt).
    Process: The text is split into chunks of 512 tokens for processing. The NER pipeline extracts disease entities and handles continuation tokens.
    Output: Extracted disease entities are written into a CSV file (biobert_entities_disease.csv) with columns Entity and Label.

Key Features:

    BIO Tagging: The script properly handles token continuation (BIO tagging) for multi-token disease names.
    Chunking: The text is processed in 512-token chunks due to model limitations.

3. biobert_drug_entities_extraction.py

This script uses the BioBERT model (d4data/biomedical-ner-all) to extract drug entities from a text file.

    Input: A large text file (combined_text.txt).
    Process: Similar to the disease entity extraction, the text is split into chunks, and the NER pipeline extracts drug entities.
    Output: Extracted drug entities are written into a CSV file (biobert_entities_drug.csv) with columns Entity and Label.

Key Features:

    BIO Tagging: It handles BIO tagging for multi-token drug names.
    Chunking: The text is processed in 512-token chunks for better efficiency.

4. compare_entities_spacy_biobert.py

This script compares the entity recognition results from the SpaCy and BioBERT models.

    Input: Three CSV files generated by the SpaCy and BioBERT scripts:
        spacy_en_ner_bc5cdr_md_entities.csv
        biobert_entities_drug.csv
        biobert_entities_disease.csv

    Process:
        Total entities are counted for each file.
        Common entities (drug and disease) between SpaCy and BioBERT are calculated.
        Unique entities are identified between the two models.

    Output:
        A summary CSV file (comparison_summary.csv) with key metrics like total, common, and unique entity counts.
        CSV files for common and unique entities between SpaCy and BioBERT:
            common_entities_Drug.csv
            common_entities_Disease.csv
            unique_entities_Drug.csv
            unique_entities_Disease.csv
        A bar graph (Bar_graph_Comparison.png) visualizing the total and common entity counts.

Key Features:

    Data Visualization: The script generates a bar graph that compares entity counts across different models.
    Entity Comparison: It provides a detailed comparison of common and unique entities between models.

Requirements

To run these scripts, you will need the following Python libraries:

    transformers
    spacy
    pandas
    matplotlib
    csv

You can install the required dependencies using the following command:

bash

pip install transformers spacy pandas matplotlib

Usage

    Extract entities using SpaCy:
        Run spacy_en_ner_bc5cdr_md_entities_extraction.py to extract drug and disease entities using SpaCy.

    Extract disease entities using BioBERT:
        Run biobert_disease_entities_extraction.py to extract disease entities using the BioBERT model.

    Extract drug entities using BioBERT:
        Run biobert_drug_entities_extraction.py to extract drug entities using the BioBERT model.

    Compare results:
        After generating the entity CSV files, run compare_entities_spacy_biobert.py to compare the results and generate summary files and a graph.

Output Files

    spacy_en_ner_bc5cdr_md_entities.csv: Entities extracted using SpaCy (diseases and drugs).
    biobert_entities_disease.csv: Disease entities extracted using BioBERT.
    biobert_entities_drug.csv: Drug entities extracted using BioBERT.
    comparison_summary.csv: Summary of total, common, and unique entities across the files.
    common_entities_Drug.csv: Common drug entities between SpaCy and BioBERT.
    common_entities_Disease.csv: Common disease entities between SpaCy and BioBERT.
    unique_entities_Drug.csv: Unique drug entities found only in SpaCy or BioBERT.
    unique_entities_Disease.csv: Unique disease entities found only in SpaCy or BioBERT.
    Bar_graph_Comparison.png: Bar graph visualizing total and common entity counts.

MyFiles
        https://charlesdarwinuni-my.sharepoint.com/:f:/g/personal/s378184_students_cdu_edu_au/Ej-nB6qv3OxHq4lk-SOiNuwBPVbamceEOtnC6t4bx1r9Sg?e=C1wtKc


James 

Chapter1 uses the provided algorithm which generates a number by changing the R,G,B channels of a provided image by adding values to the original R,G,B 
channels and generates a new images using the new results from the R,G,B channels
The program uses OpenCv module for the image processing.

Chapter2 using a specified string "s", this is a program which breaks the given string
into long strings and number, converting the number strings into ASCII decimal values,and also converts the 
Upper case letters in the sting to ASCII decimal values,

Also in chapter2 code, a program is written to decrypt and print a cryptogram using shift key values

